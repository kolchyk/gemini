import streamlit as st
from google.genai import types
import base64
import os
import mimetypes
import time

# Import from local modules
from gemini_image_generator.config import CUSTOM_CSS, PROMPT_WOMEN, PROMPT_MEN
from gemini_image_generator.client import get_gemini_client
from gemini_image_generator.file_utils import save_uploaded_file
from gemini_image_generator.telegram_utils import send_telegram_log, send_telegram_text_log
from gemini_image_generator.research_agent import start_research, check_research_status

# Page configuration
st.set_page_config(
    page_title="NanaBanana for Darnytsia",
    page_icon="üé®",
    layout="wide"
)

# Custom CSS for modern UI
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# Header container
with st.container():
    st.markdown('<div class="main-title">', unsafe_allow_html=True)
    st.title("üçå NanaBanana for Darnytsia")
    st.markdown('</div>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –æ–¥–Ω–µ –∞–±–æ –∫—ñ–ª—å–∫–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–∞ –≤–≤–µ–¥—ñ—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –Ω–æ–≤–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è</p>', unsafe_allow_html=True)


# Initialize session state for research agent
if 'research_interaction_id' not in st.session_state:
    st.session_state['research_interaction_id'] = None
if 'research_query' not in st.session_state:
    st.session_state['research_query'] = None
if 'research_status' not in st.session_state:
    st.session_state['research_status'] = None
if 'research_auto_polling' not in st.session_state:
    st.session_state['research_auto_polling'] = False
if 'research_result' not in st.session_state:
    st.session_state['research_result'] = None
if 'research_error' not in st.session_state:
    st.session_state['research_error'] = None

# Initialize session state for Gemini 3 Pro chat
if 'gemini_chat_history' not in st.session_state:
    st.session_state['gemini_chat_history'] = []
if 'chat_thinking_level' not in st.session_state:
    st.session_state['chat_thinking_level'] = 'low'
if 'chat_temperature' not in st.session_state:
    st.session_state['chat_temperature'] = 0.7

# Initialize session state for image generator settings
if 'image_aspect_ratio' not in st.session_state:
    st.session_state['image_aspect_ratio'] = "1:1"
if 'image_resolution' not in st.session_state:
    st.session_state['image_resolution'] = "1K"
if 'image_temperature' not in st.session_state:
    st.session_state['image_temperature'] = 1.0

# Create tabs
tab1, tab2, tab3 = st.tabs(["üé® –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω—å", "üîç Deep Research Agent", "üí¨ –ß–∞—Ç –∑ Gemini 3 Pro"])

# Default settings
model_name = "gemini-3-pro-image-preview"

# ========== TAB 1: IMAGE GENERATOR ==========
with tab1:
    # Create two-column layout: main content (3) and settings panel (1)
    col_main, col_settings = st.columns([3, 1])
    
    with col_main:
        # Quick start guide
        with st.expander("üìñ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç", expanded=False):
            st.markdown("""
            **–Ø–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ç–∏—Å—å:**
            1. **–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∏** (–∫—Ä–∞—â–µ 1‚Äì3 —Ñ–æ—Ç–æ –æ–±–ª–∏—á—á—è, —Å—Ö–æ–∂–∏–π —Ä–∞–∫—É—Ä—Å/—Å–≤—ñ—Ç–ª–æ)
            2. **–û–±–µ—Ä—ñ—Ç—å —à–∞–±–ª–æ–Ω** (–ñ—ñ–Ω–∫–∏/–ß–æ–ª–æ–≤—ñ–∫–∏) —ñ **–≤—ñ–¥—Ä–µ–¥–∞–≥—É–π—Ç–µ –ø—Ä–æ–º–ø—Ç** –ø—ñ–¥ –∑–∞–¥–∞—á—É
            3. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å **¬´–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è¬ª** ‚Üí –ø–æ—Ç—ñ–º **¬´–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏¬ª**
            
            **–ü–æ—Ä–∞–¥–∞:** —è–∫—â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –≤–ª—É—á–∏–≤ ‚Äî —Å–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç–∏ –æ–¥—è–≥/—Ñ–æ–Ω/—Å–≤—ñ—Ç–ª–æ –∞–±–æ –¥–æ–¥–∞–π—Ç–µ —â–µ –æ–¥–∏–Ω —Ä–µ—Ñ–µ—Ä–µ–Ω—Å.
            """)
        
        st.markdown("---")
        
        # Section 1: Reference image upload (top)
        st.subheader("üì§ –ö—Ä–æ–∫ 1: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")
        uploaded_files = st.file_uploader(
            "–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –æ–¥–Ω–µ –∞–±–æ –∫—ñ–ª—å–∫–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)",
            type=['jpg', 'jpeg', 'png', 'bmp', 'gif'],
            accept_multiple_files=True,
            help=(
                "–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ: 1‚Äì3 —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∏ –∑ –æ–±–ª–∏—á—á—è–º/–ø–æ—Ä—Ç—Ä–µ—Ç–æ–º. "
                "–ß–∏–º –±–ª–∏–∂—á–µ —Ä–∞–∫—É—Ä—Å —ñ –æ—Å–≤—ñ—Ç–ª–µ–Ω–Ω—è –¥–æ –±–∞–∂–∞–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É ‚Äî —Ç–∏–º –∫—Ä–∞—â–µ. "
                "–ú–æ–∂–Ω–∞ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –±–µ–∑ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ñ–≤, –∞–ª–µ –ø—Ä–æ–º–ø—Ç –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π."
            ),
            key="reference_images"
        )
        st.caption(
            "üí° –ü—ñ–¥–∫–∞–∑–∫–∞: —è–∫—â–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ñ–≤ –Ω–µ–º–∞—î ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –º–æ–∂–ª–∏–≤–∞, –∞–ª–µ —Å—Ö–æ–∂—ñ—Å—Ç—å/—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –º–æ–∂–µ –±—É—Ç–∏ –≥—ñ—Ä—à–æ—é."
        )
        
        # Display uploaded reference images immediately
        if uploaded_files:
            num_files = len(uploaded_files)
            st.markdown("---")
            if num_files == 1:
                st.caption(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ 1 —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")
                st.image(uploaded_files[0], caption="–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", width='stretch')
            else:
                st.caption(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {num_files} —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å")
                # Display images in columns for better layout
                cols = st.columns(min(3, num_files))
                for idx, uploaded_file in enumerate(uploaded_files):
                    with cols[idx % len(cols)]:
                        st.image(uploaded_file, caption=f"–†–µ—Ñ–µ—Ä–µ–Ω—Å {idx + 1}: {uploaded_file.name}", width='stretch')
        
        st.markdown("---")

        # Section 2: Prompt input (middle)
        st.subheader("‚úçÔ∏è –ö—Ä–æ–∫ 2: –ü—Ä–æ–º–ø—Ç")
        
        # Initialize session state for prompt management
        if 'prompt_type' not in st.session_state:
            st.session_state['prompt_type'] = 'women'
        if 'edited_prompt_women' not in st.session_state:
            st.session_state['edited_prompt_women'] = None
        if 'edited_prompt_men' not in st.session_state:
            st.session_state['edited_prompt_men'] = None
        
        # Prompt type selector
        prompt_type = st.radio(
            "–¢–∏–ø –ø—Ä–æ–º–ø—Ç—É:",
            ["–ñ—ñ–Ω–∫–∏", "–ß–æ–ª–æ–≤—ñ–∫–∏"],
            index=0 if st.session_state['prompt_type'] == 'women' else 1,
            horizontal=True,
            help="–û–±–µ—Ä—ñ—Ç—å —à–∞–±–ª–æ–Ω —ñ –≤—ñ–¥—Ä–µ–¥–∞–≥—É–π—Ç–µ —Ç–µ–∫—Å—Ç –Ω–∏–∂—á–µ. –í–∞—à—ñ –ø—Ä–∞–≤–∫–∏ –∑–±–µ—Ä–µ–∂—É—Ç—å—Å—è –æ–∫—Ä–µ–º–æ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç–∏–ø—É.",
            key="prompt_type_selector"
        )
        
        # Update session state when selection changes
        current_prompt_type = 'women' if prompt_type == "–ñ—ñ–Ω–∫–∏" else 'men'
        if current_prompt_type != st.session_state['prompt_type']:
            # Save current edited prompt before switching
            old_prompt_key = f"prompt_text_area_{st.session_state['prompt_type']}"
            if old_prompt_key in st.session_state:
                if st.session_state['prompt_type'] == 'women':
                    st.session_state['edited_prompt_women'] = st.session_state[old_prompt_key]
                else:
                    st.session_state['edited_prompt_men'] = st.session_state[old_prompt_key]
            
            st.session_state['prompt_type'] = current_prompt_type
        
        # Determine which prompt to use
        if st.session_state['prompt_type'] == 'women':
            base_prompt = PROMPT_WOMEN
            edited_prompt = st.session_state['edited_prompt_women']
        else:
            base_prompt = PROMPT_MEN
            edited_prompt = st.session_state['edited_prompt_men']
        
        # Use edited prompt if available, otherwise use base prompt
        current_prompt_value = edited_prompt if edited_prompt is not None else base_prompt
        
        # Text area for prompt editing - use dynamic key based on prompt type
        prompt_key = f"prompt_text_area_{st.session_state['prompt_type']}"
        prompt = st.text_area(
            "–û–ø–∏—à—ñ—Ç—å, —â–æ –≤–∏ —Ö–æ—á–µ—Ç–µ –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏:",
            value=current_prompt_value,
            height=200,
            placeholder="–ù–∞–ø—Ä–∏–∫–ª–∞–¥: Keep the facial features of the person in the uploaded image exactly consistent...",
            help=(
                "–ü–æ—Ä–∞–¥–∞: –∫—Ä–∞—â–µ –æ–ø–∏—Å—É–≤–∞—Ç–∏: (1) —â–æ –Ω–µ–∑–º—ñ–Ω–Ω–µ (–æ–±–ª–∏—á—á—è), (2) –æ–¥—è–≥/—Å—Ç–∏–ª—å, (3) —Ñ–æ–Ω, (4) —Å–≤—ñ—Ç–ª–æ/–∫–∞–º–µ—Ä–∞, (5) —â–æ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–æ."
            ),
            key=prompt_key
        )

        col_a, col_b = st.columns([1, 1])
        with col_a:
            if st.button("‚Ü©Ô∏è –°–∫–∏–Ω—É—Ç–∏ –ø—Ä–æ–º–ø—Ç –¥–æ —à–∞–±–ª–æ–Ω—É", width='stretch'):
                if st.session_state['prompt_type'] == 'women':
                    st.session_state['edited_prompt_women'] = PROMPT_WOMEN
                else:
                    st.session_state['edited_prompt_men'] = PROMPT_MEN
                st.rerun()
        with col_b:
            if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç", width='stretch'):
                st.session_state.pop('generated_image', None)
                st.rerun()
    
        # Save edited prompt when user edits (update session state after text_area is rendered)
        if st.session_state['prompt_type'] == 'women':
            st.session_state['edited_prompt_women'] = prompt
        else:
            st.session_state['edited_prompt_men'] = prompt
        
        st.markdown("---")
        
        # Generate button - more prominent placement
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            generate_button = st.button("üöÄ –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", type="primary", width='stretch')
    
    # Right settings panel
    with col_settings:
        st.markdown('<div class="settings-panel">', unsafe_allow_html=True)
        st.markdown("### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó")
        
        aspect_ratio = st.selectbox(
            "–°–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω:",
            options=["1:1", "16:9", "9:16", "4:3", "3:4"],
            index=["1:1", "16:9", "9:16", "4:3", "3:4"].index(st.session_state['image_aspect_ratio']),
            help="–í–∏–±–µ—Ä—ñ—Ç—å —Å–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω –¥–ª—è –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
            key="image_aspect_ratio_selector"
        )
        st.session_state['image_aspect_ratio'] = aspect_ratio
        
        resolution = st.selectbox(
            "–†–æ–∑–¥—ñ–ª—å–Ω–∞ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å:",
            options=["1K", "2K", "4K"],
            index=["1K", "2K", "4K"].index(st.session_state['image_resolution']),
            help="–í–∏–±–µ—Ä—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª—å–Ω—É –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (–≤–∏—â–∞ = –∫—Ä–∞—â–∞ —è–∫—ñ—Å—Ç—å, –∞–ª–µ –¥–æ–≤—à–µ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è)",
            key="image_resolution_selector"
        )
        st.session_state['image_resolution'] = resolution
        
        temperature = st.slider(
            "Temperature:",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state['image_temperature'],
            step=0.05,
            help="–ö–æ–Ω—Ç—Ä–æ–ª—é—î –≤–∏–ø–∞–¥–∫–æ–≤—ñ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó (0.0 = –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ, 1.0 = –±—ñ–ª—å—à–µ –≤–∞—Ä—ñ–∞—Ü—ñ–π)",
            key="image_temperature_slider"
        )
        st.session_state['image_temperature'] = temperature
        
        st.divider()
        
        with st.expander("üí° –ü—ñ–¥–∫–∞–∑–∫–∏"):
            st.markdown("""
            **–î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —Å—Ö–æ–∂–æ—Å—Ç—ñ:**
            - –î–æ–¥–∞–π—Ç–µ *keep facial features exactly consistent*
            - –û–ø–∏—à—ñ—Ç—å —Ä–∞–∫—É—Ä—Å (front/3-4 view)
            
            **–î–ª—è –±—ñ–∑–Ω–µ—Å-–ø–æ—Ä—Ç—Ä–µ—Ç–∞:**
            - –£—Ç–æ—á–Ω—ñ—Ç—å *studio backdrop*
            - –î–æ–¥–∞–π—Ç–µ *three-point lighting*
            - –í–∫–∞–∂—ñ—Ç—å *85mm lens*
            
            **–©–æ–± –ø—Ä–∏–±—Ä–∞—Ç–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏:**
            - –î–æ–¥–∞–π—Ç–µ *no extra people, no text, no watermark*
            
            **–Ø–∫—â–æ —Ñ–æ–Ω "–±—Ä—É–¥–Ω–∏–π":**
            - –í–∫–∞–∂—ñ—Ç—å *clean solid background, subtle gradient, no objects*
            """)
        
        st.markdown('</div>', unsafe_allow_html=True)

    # Generate image when button is clicked
    if generate_button:
        # Use settings from session state
        aspect_ratio = st.session_state['image_aspect_ratio']
        resolution = st.session_state['image_resolution']
        temperature = st.session_state['image_temperature']
        
        with col_main:
            # Validation - prompt is mandatory
            if not prompt or not prompt.strip():
                st.error("‚ö†Ô∏è –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å –ø—Ä–æ–º–ø—Ç. –ü—Ä–æ–º–ø—Ç —î –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.")
                st.stop()
            
            # Source images are optional - just show info if provided
            if uploaded_files and len(uploaded_files) > 0:
                st.info(f"‚ÑπÔ∏è –ë—É–¥–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ {len(uploaded_files)} —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å")
            
            st.markdown("---")
            
            # Section 3: Result display (bottom)
            st.subheader("üé® –†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó")
            
            # Show progress
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                status_text.text("üîÑ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç–∞ Gemini...")
                progress_bar.progress(10)
                client = get_gemini_client()
                
                # Prepare file parts
                file_parts = []
                saved_file_metadata = []  # –°–ø–∏—Å–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                
                if uploaded_files and len(uploaded_files) > 0:
                    num_files = len(uploaded_files)
                    for idx, uploaded_file in enumerate(uploaded_files):
                        status_text.text(f"üì§ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è {idx + 1} –∑ {num_files}...")
                        progress_bar.progress(10 + int(20 * (idx + 1) / num_files))
                        
                        try:
                            file_metadata = save_uploaded_file(uploaded_file)
                            saved_file_metadata.append(file_metadata)
                        except Exception:
                            pass
                        
                        # Determine MIME type
                        mime_type, _ = mimetypes.guess_type(uploaded_file.name)
                        if not mime_type:
                            ext = os.path.splitext(uploaded_file.name)[1].lower()
                            mime_map = {
                                '.jpg': 'image/jpeg',
                                '.jpeg': 'image/jpeg',
                                '.png': 'image/png',
                                '.gif': 'image/gif',
                                '.bmp': 'image/bmp'
                            }
                            mime_type = mime_map.get(ext, 'image/jpeg')
                        
                        # Upload file to Gemini
                        uploaded_file.seek(0)  # Reset file pointer
                        uploaded_gemini_file = client.files.upload(
                            file=uploaded_file,
                            config={'mime_type': mime_type}
                        )
                        file_parts.append(
                            types.Part(file_data=types.FileData(file_uri=uploaded_gemini_file.uri))
                        )
                else:
                    progress_bar.progress(30)
                
                # Create parts list (files + text)
                parts_list = file_parts.copy()
                parts_list.append(types.Part.from_text(text=prompt))
                
                # Create Content object matching the example format
                contents = [
                    types.Content(
                        role="user",
                        parts=parts_list,
                    ),
                ]
                
                status_text.text("üé® –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è...")
                progress_bar.progress(50)
                
                # Prepare tools (GoogleSearch)
                tools = [
                    types.Tool(googleSearch=types.GoogleSearch()),
                ]
                
                # Generate content with streaming
                generate_content_config = types.GenerateContentConfig(
                    response_modalities=["IMAGE", "TEXT"],
                    temperature=temperature,
                    image_config=types.ImageConfig(
                        aspect_ratio=aspect_ratio,
                        image_size=resolution,
                    ),
                    tools=tools,
                )
                
                # Process streaming response
                image_bytes = None
                text_output = []
                file_index = 0
                
                # Create a placeholder for text output
                text_placeholder = st.empty()
                
                status_text.text("üì• –û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (streaming)...")
                progress_bar.progress(60)
                
                for chunk in client.models.generate_content_stream(
                    model=model_name,
                    contents=contents,
                    config=generate_content_config,
                ):
                    if (
                        chunk.candidates is None
                        or chunk.candidates[0].content is None
                        or chunk.candidates[0].content.parts is None
                    ):
                        continue
                    
                    # Check for image data
                    if (chunk.candidates[0].content.parts[0].inline_data 
                        and chunk.candidates[0].content.parts[0].inline_data.data):
                        inline_data = chunk.candidates[0].content.parts[0].inline_data
                        data_buffer = inline_data.data
                        
                        # Convert string to bytes if needed
                        if isinstance(data_buffer, str):
                            data_buffer = base64.b64decode(data_buffer)
                        
                        if data_buffer:
                            image_bytes = data_buffer
                            file_index += 1
                            progress_bar.progress(90)
                            status_text.text("‚úÖ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ—Ç—Ä–∏–º–∞–Ω–æ!")
                    else:
                        # Check for text output (matching example format)
                        if hasattr(chunk, 'text') and chunk.text:
                            text_output.append(chunk.text)
                            # Display accumulated text
                            if text_output:
                                text_placeholder.text("".join(text_output))
                
                progress_bar.progress(100)
                status_text.text("‚úÖ –ì–æ—Ç–æ–≤–æ!")
                
                # Display text output if available
                if text_output:
                    full_text = "".join(text_output)
                    if full_text.strip():
                        with st.expander("üìù –¢–µ–∫—Å—Ç–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å", expanded=False):
                            st.markdown(full_text)
                
                if image_bytes:
                    # Display generated image
                    st.success("üéâ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ!")
                    st.info(
                        "**–©–æ –¥–∞–ª—ñ:** –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å **¬´–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è¬ª** –Ω–∏–∂—á–µ.\n\n"
                        "**–Ø–∫ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**\n"
                        "- –¥–æ–¥–∞–π—Ç–µ 1‚Äì2 —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∏ –∑ –±–ª–∏–∂—á–∏–º —Ä–∞–∫—É—Ä—Å–æ–º;\n"
                        "- —É—Ç–æ—á–Ω—ñ—Ç—å —Ñ–æ–Ω (solid/gradient) —ñ —Å–≤—ñ—Ç–ª–æ (three-point);\n"
                        "- –¥–æ–¥–∞–π—Ç–µ –æ–±–º–µ–∂–µ–Ω–Ω—è: *no text, no watermark, no extra people*."
                    )
                    st.image(image_bytes, caption="–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", width='stretch')
                    
                    # Download button
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        st.download_button(
                            label="üíæ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
                            data=image_bytes,
                            file_name="generated_image.jpg",
                            mime="image/jpeg",
                            width='stretch'
                        )
                    
                    # Store in session state for persistence
                    st.session_state['generated_image'] = image_bytes
                    
                    try:
                        original_images_bytes = []
                        if uploaded_files:
                            for uploaded_file in uploaded_files:
                                uploaded_file.seek(0)
                                original_images_bytes.append(uploaded_file.read())
                        
                        send_telegram_log(original_images_bytes, image_bytes, prompt, saved_file_metadata if saved_file_metadata else None)
                    except Exception:
                        pass
                elif not text_output:
                    st.error("‚ùå –ü–æ–º–∏–ª–∫–∞: –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")
            
            except Exception as e:
                st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")
                st.exception(e)
            finally:
                progress_bar.empty()
                status_text.empty()
    
    # Display previously generated image if exists
    with col_main:
        if 'generated_image' in st.session_state and not generate_button:
            st.markdown("---")
            st.subheader("üì∏ –û—Å—Ç–∞–Ω–Ω—î –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")
            st.image(st.session_state['generated_image'], caption="–û—Å—Ç–∞–Ω–Ω—î –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", width='stretch')
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.download_button(
                    label="üíæ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è",
                    data=st.session_state['generated_image'],
                    file_name="generated_image.jpg",
                    mime="image/jpeg",
                    width='stretch'
                )

# ========== TAB 2: DEEP RESEARCH AGENT ==========
with tab2:
    # Create two-column layout: main content (3) and settings panel (1)
    col_main, col_settings = st.columns([3, 1])
    
    with col_main:
        st.subheader("üîç Deep Research Agent")
        st.markdown("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ Deep Research Agent –¥–ª—è –≥–ª–∏–±–æ–∫–æ–≥–æ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è —Ç–µ–º –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –∑–±–æ—Ä–æ–º —Ç–∞ –∞–Ω–∞–ª—ñ–∑–æ–º —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó")
        
        with st.expander("üìñ –Ø–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ç–∏—Å—å", expanded=False):
            st.markdown("""
            **–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è:**
            1. **–í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç** –¥–ª—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –ø—Ä–æ —ñ—Å—Ç–æ—Ä—ñ—é —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ–π, –ø–æ–¥—ñ—ó, –∞–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö)
            2. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å **¬´–ü–æ—á–∞—Ç–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è¬ª** ‚Äî –∞–≥–µ–Ω—Ç –ø–æ—á–Ω–µ —Ä–æ–±–æ—Ç—É —É —Ñ–æ–Ω–æ–≤–æ–º—É —Ä–µ–∂–∏–º—ñ
            3. **–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞—Ç—É—Å—É** ‚Äî —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–≤—ñ—Ä—è—î –ø—Ä–æ–≥—Ä–µ—Å –∫–æ–∂–Ω—ñ 10 —Å–µ–∫—É–Ω–¥
            4. –ö–æ–ª–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è, –≤–∏ –ø–æ–±–∞—á–∏—Ç–µ **—Ñ—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç** –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            """)
        
        st.markdown("---")
        
        # Input section
        st.subheader("üìù –ó–∞–ø–∏—Ç –¥–ª—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è")
        research_query = st.text_area(
            "–í–≤–µ–¥—ñ—Ç—å —Ç–µ–º—É –∞–±–æ –ø–∏—Ç–∞–Ω–Ω—è –¥–ª—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è:",
            value=st.session_state['research_query'] if st.session_state['research_query'] else "",
            height=150,
            placeholder="–ù–∞–ø—Ä–∏–∫–ª–∞–¥: Research the history of the Google TPUs with a focus on 2025 and 2026.",
            help="–û–ø–∏—à—ñ—Ç—å —Ç–µ–º—É –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –¥–µ—Ç–∞–ª—å–Ω–æ –¥–ª—è –∫—Ä–∞—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.",
            key="research_query_input"
        )
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            start_research_button = st.button("üöÄ –ü–æ—á–∞—Ç–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è", type="primary", width='stretch')
        
        # Handle start research button
        if start_research_button:
            if not research_query or not research_query.strip():
                st.error("‚ö†Ô∏è –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç –¥–ª—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è")
            else:
                try:
                    client = get_gemini_client()
                    interaction_id, status = start_research(research_query.strip(), client)
                    st.session_state['research_interaction_id'] = interaction_id
                    st.session_state['research_query'] = research_query.strip()
                    st.session_state['research_status'] = status
                    st.session_state['research_auto_polling'] = True
                    st.session_state['research_result'] = None
                    st.session_state['research_error'] = None
                    st.session_state['research_logged_to_telegram'] = False
                    st.session_state['research_last_poll_time'] = 0  # Reset poll timer
                    st.success(f"‚úÖ –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è —Ä–æ–∑–ø–æ—á–∞—Ç–æ! Interaction ID: {interaction_id}")
                    st.rerun()
                except Exception as e:
                    st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")
        
        st.markdown("---")
        
        # Status and results section
        if st.session_state['research_interaction_id']:
            st.subheader("üìä –°—Ç–∞—Ç—É—Å –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è")
            
            interaction_id = st.session_state['research_interaction_id']
            current_status = st.session_state['research_status']
            
            # Display interaction ID
            st.caption(f"**Interaction ID:** `{interaction_id}`")
            
            # Status display
            if current_status == "pending":
                st.info("‚è≥ **–°—Ç–∞—Ç—É—Å:** –û—á—ñ–∫—É–≤–∞–Ω–Ω—è...")
            elif current_status == "processing":
                st.info("üîÑ **–°—Ç–∞—Ç—É—Å:** –û–±—Ä–æ–±–∫–∞...")
            elif current_status == "completed":
                st.success("‚úÖ **–°—Ç–∞—Ç—É—Å:** –ó–∞–≤–µ—Ä—à–µ–Ω–æ!")
            elif current_status in ["failed", "cancelled"]:
                st.error(f"‚ùå **–°—Ç–∞—Ç—É—Å:** {current_status.capitalize()}")
            else:
                st.info(f"‚ÑπÔ∏è **–°—Ç–∞—Ç—É—Å:** {current_status}")
            
            st.markdown("---")
            
            # Results display
            if st.session_state['research_result']:
                st.subheader("üìÑ –§—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç")
                
                result_text = st.session_state['research_result']
                
                # Display result in expandable section
                with st.expander("üîç –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –∑–≤—ñ—Ç", expanded=True):
                    st.markdown(result_text)
                
                # Download button
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    st.download_button(
                        label="üíæ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–≤—ñ—Ç",
                        data=result_text.encode('utf-8'),
                        file_name=f"research_report_{interaction_id[:8]}.md",
                        mime="text/markdown",
                        width='stretch'
                    )
            
            elif current_status in ["failed", "cancelled"]:
                st.warning("‚ö†Ô∏è –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—è –∑ –ø–æ–º–∏–ª–∫–æ—é –∞–±–æ –±—É–ª–æ —Å–∫–∞—Å–æ–≤–∞–Ω–æ.")
                if st.session_state['research_error']:
                    st.error(f"**–î–µ—Ç–∞–ª—ñ –ø–æ–º–∏–ª–∫–∏:** {st.session_state['research_error']}")
            
            elif current_status == "completed" and not st.session_state['research_result']:
                st.info("‚ÑπÔ∏è –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –∞–ª–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —â–µ –Ω–µ –æ—Ç—Ä–∏–º–∞–Ω–æ. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å ¬´–û–Ω–æ–≤–∏—Ç–∏ —Å—Ç–∞—Ç—É—Å¬ª.")
        
        else:
            st.info("üí° –í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç –≤–∏—â–µ —Ç–∞ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å ¬´–ü–æ—á–∞—Ç–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è¬ª, —â–æ–± —Ä–æ–∑–ø–æ—á–∞—Ç–∏ —Ä–æ–±–æ—Ç—É –∑ Deep Research Agent.")
    
    # Right settings panel
    with col_settings:
        st.markdown('<div class="settings-panel">', unsafe_allow_html=True)
        st.markdown("### –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è")
        
        if st.session_state['research_interaction_id']:
            interaction_id = st.session_state['research_interaction_id']
            current_status = st.session_state['research_status']
            
            st.markdown(f"**Interaction ID:**")
            st.code(interaction_id[:16] + "...", language=None)
            
            st.divider()
            
            # Auto-polling status
            if st.session_state['research_auto_polling']:
                st.success("üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è: –£–≤—ñ–º–∫–Ω–µ–Ω–æ")
            else:
                st.info("‚è∏Ô∏è –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è: –í–∏–º–∫–Ω–µ–Ω–æ")
            
            st.divider()
            
            # Control buttons
            if st.button("üîÑ –û–Ω–æ–≤–∏—Ç–∏ —Å—Ç–∞—Ç—É—Å", width='stretch', use_container_width=True):
                try:
                    client = get_gemini_client()
                    status, result, error = check_research_status(interaction_id, client)
                    st.session_state['research_status'] = status
                    if result:
                        st.session_state['research_result'] = result
                        if not st.session_state.get('research_logged_to_telegram'):
                            send_telegram_text_log(result, f"üîç Deep Research: {st.session_state['research_query']}")
                            st.session_state['research_logged_to_telegram'] = True
                    if error:
                        st.session_state['research_error'] = error
                    st.rerun()
                except Exception as e:
                    st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")
            
            if st.session_state['research_auto_polling']:
                if st.button("‚èπÔ∏è –ó—É–ø–∏–Ω–∏—Ç–∏ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥", width='stretch', use_container_width=True):
                    st.session_state['research_auto_polling'] = False
                    st.rerun()
            else:
                if st.button("üîÑ –í—ñ–¥–Ω–æ–≤–∏—Ç–∏ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥", width='stretch', use_container_width=True):
                    st.session_state['research_auto_polling'] = True
                    st.rerun()
            
            # Auto-polling logic
            if st.session_state['research_auto_polling'] and current_status not in ["completed", "failed", "cancelled"]:
                # Initialize last poll time if not exists
                if 'research_last_poll_time' not in st.session_state:
                    st.session_state['research_last_poll_time'] = 0
                
                current_time = time.time()
                time_since_last_poll = current_time - st.session_state['research_last_poll_time']
                
                # Poll if 10 seconds have passed since last poll or if this is the first poll
                if time_since_last_poll >= 10 or st.session_state['research_last_poll_time'] == 0:
                    try:
                        client = get_gemini_client()
                        status, result, error = check_research_status(interaction_id, client)
                        st.session_state['research_last_poll_time'] = current_time
                        
                        if status != current_status:
                            st.session_state['research_status'] = status
                            if result:
                                st.session_state['research_result'] = result
                                if not st.session_state.get('research_logged_to_telegram'):
                                    send_telegram_text_log(result, f"üîç Deep Research: {st.session_state['research_query']}")
                                    st.session_state['research_logged_to_telegram'] = True
                            if error:
                                st.session_state['research_error'] = error
                            st.rerun()
                        elif result and not st.session_state['research_result']:
                            # Status same but we got a result we didn't have before
                            st.session_state['research_result'] = result
                            if not st.session_state.get('research_logged_to_telegram'):
                                send_telegram_text_log(result, f"üîç Deep Research: {st.session_state['research_query']}")
                                st.session_state['research_logged_to_telegram'] = True
                            st.rerun()
                        elif error and not st.session_state['research_error']:
                            # Status same but we got an error we didn't have before
                            st.session_state['research_error'] = error
                            st.rerun()
                        else:
                            # Status unchanged, schedule auto-refresh using JavaScript
                            st.markdown(
                                f"""
                                <script>
                                    setTimeout(function() {{
                                        window.location.reload();
                                    }}, 10000);
                                </script>
                                """,
                                unsafe_allow_html=True
                            )
                            st.caption("‚è±Ô∏è –û–Ω–æ–≤–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ 10 —Å–µ–∫...")
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞: {str(e)}")
                        st.session_state['research_auto_polling'] = False
                else:
                    # Show countdown until next poll
                    seconds_until_next = int(10 - time_since_last_poll)
                    st.markdown(
                        f"""
                        <script>
                            setTimeout(function() {{
                                window.location.reload();
                            }}, {seconds_until_next * 1000});
                        </script>
                        """,
                        unsafe_allow_html=True
                    )
                    st.caption(f"‚è±Ô∏è –ß–µ—Ä–µ–∑ {seconds_until_next} —Å–µ–∫...")
        else:
            st.info("üí° –ü–æ—á–Ω—ñ—Ç—å –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ —Å—Ç–∞—Ç—É—Å —Ç–∞ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Ç—É—Ç.")
        
        st.markdown('</div>', unsafe_allow_html=True)

# ========== TAB 3: GEMINI 3 PRO CHAT ==========
with tab3:
    # Create two-column layout: main content (3) and settings panel (1)
    col_main, col_settings = st.columns([3, 1])
    
    with col_main:
        st.subheader("üí¨ –ß–∞—Ç –∑ Gemini 3 Pro")
        st.markdown("–°–ø—ñ–ª–∫—É–π—Ç–µ—Å—è –∑ Gemini 3 Pro –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–µ—Ç–∞–ª—å–Ω–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π —Ç–∞ –∞–Ω–∞–ª—ñ–∑—É")
        
        with st.expander("üìñ –Ø–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ç–∏—Å—å", expanded=False):
            st.markdown("""
            **–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è:**
            1. **–í–≤–µ–¥—ñ—Ç—å –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è** –≤ –ø–æ–ª–µ –≤–Ω–∏–∑—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏
            2. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å **Enter** –∞–±–æ –∫–Ω–æ–ø–∫—É –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ ‚Äî Gemini 3 Pro –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç—å —É —Ä–µ–∂–∏–º—ñ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —á–∞—Å—É
            3. **–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –º–∏—Å–ª–µ–Ω–Ω—è:** –æ–±–µ—Ä—ñ—Ç—å —Ä—ñ–≤–µ–Ω—å –º–∏—Å–ª–µ–Ω–Ω—è (low/high) –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—é –≥–ª–∏–±–∏–Ω–∏ –∞–Ω–∞–ª—ñ–∑—É
            4. **–Ü—Å—Ç–æ—Ä—ñ—è —á–∞—Ç—É:** –≤—Å—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –ø—Ä–æ—Ç—è–≥–æ–º —Å–µ—Å—ñ—ó
            """)
        
        st.markdown("---")
        
        # Create scrollable container for chat messages
        chat_messages_container = st.container()
        with chat_messages_container:
            st.markdown('<div class="chat-messages-scrollable">', unsafe_allow_html=True)
            # Display chat history
            for message in st.session_state['gemini_chat_history']:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Chat input (will be rendered at bottom by Streamlit, CSS will keep it fixed)
        if prompt := st.chat_input("–í–≤–µ–¥—ñ—Ç—å –≤–∞—à–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è..."):
            # Add user message to history
            st.session_state['gemini_chat_history'].append({"role": "user", "content": prompt})
            
            # Display user message
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Generate response
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                
                try:
                    client = get_gemini_client()
                    
                    # Prepare contents from chat history
                    contents = []
                    for msg in st.session_state['gemini_chat_history']:
                        contents.append(
                            types.Content(
                                role=msg["role"],
                                parts=[types.Part.from_text(text=msg["content"])]
                            )
                        )
                    
                    # Generate content config with thinking_config
                    generate_content_config = types.GenerateContentConfig(
                        temperature=st.session_state['chat_temperature'],
                        max_output_tokens=8192,
                        thinking_config=types.ThinkingConfig(
                            thinking_level=st.session_state['chat_thinking_level']
                        ),
                    )
                    
                    # Stream response
                    for chunk in client.models.generate_content_stream(
                        model="gemini-3-pro-preview",
                        contents=contents,
                        config=generate_content_config,
                    ):
                        if (
                            chunk.candidates is None
                            or chunk.candidates[0].content is None
                            or chunk.candidates[0].content.parts is None
                        ):
                            continue
                        
                        # Extract text from chunk
                        chunk_text = ""
                        for part in chunk.candidates[0].content.parts:
                            if hasattr(part, 'text') and part.text:
                                chunk_text += part.text
                        
                        if chunk_text:
                            full_response += chunk_text
                            message_placeholder.markdown(full_response + "‚ñå")
                    
                    # Final update without cursor
                    message_placeholder.markdown(full_response)
                    
                    # Add assistant response to history
                    st.session_state['gemini_chat_history'].append({"role": "assistant", "content": full_response})
                    
                    try:
                        chat_log_text = f"User: {prompt}\n\nAssistant: {full_response}"
                        send_telegram_text_log(chat_log_text, title="üí¨ Gemini 3 Pro Chat")
                    except Exception:
                        pass
                        
                except Exception as e:
                    error_message = f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}"
                    message_placeholder.error(error_message)
                    st.exception(e)
    
    # Right settings panel
    with col_settings:
        st.markdown('<div class="settings-panel">', unsafe_allow_html=True)
        st.markdown("### –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ")
        
        thinking_level = st.selectbox(
            "–†—ñ–≤–µ–Ω—å –º–∏—Å–ª–µ–Ω–Ω—è:",
            options=["low", "high"],
            index=0 if st.session_state['chat_thinking_level'] == 'low' else 1,
            help="Low = —à–≤–∏–¥—à—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ, High = –≥–ª–∏–±—à–∏–π –∞–Ω–∞–ª—ñ–∑ —Ç–∞ –º–∏—Å–ª–µ–Ω–Ω—è",
            key="thinking_level_selector"
        )
        st.session_state['chat_thinking_level'] = thinking_level
        
        temperature = st.slider(
            "Temperature:",
            min_value=0.0,
            max_value=2.0,
            value=st.session_state['chat_temperature'],
            step=0.1,
            help="–ö–æ–Ω—Ç—Ä–æ–ª—é—î –≤–∏–ø–∞–¥–∫–æ–≤—ñ—Å—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π (0.0 = –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–æ, 2.0 = –±—ñ–ª—å—à–µ –≤–∞—Ä—ñ–∞—Ü—ñ–π)",
            key="chat_temperature_slider"
        )
        st.session_state['chat_temperature'] = temperature
        
        st.divider()
        
        st.markdown("**–ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó:**")
        st.caption(f"Max tokens: 8192")
        st.caption(f"Model: gemini-3-pro-preview")
        
        st.divider()
        
        if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é —á–∞—Ç—É", width='stretch', use_container_width=True):
            st.session_state['gemini_chat_history'] = []
            st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)

